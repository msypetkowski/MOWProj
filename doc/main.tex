\documentclass[a4paper]{article}

\usepackage[a4paper,  margin=1.0in]{geometry}

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}


\usepackage[utf8]{inputenc}
\begin{document}


\title{Prediction of student's alcohol consumption with random forests}

\author{Mikołaj Ciesielski, Michał Sypetkowski}
\maketitle


\section{Data}

Research is done with dataset: \url{https://www.kaggle.com/uciml/student-alcohol-consumption/}.

The data were obtained in a survey of students
math and portuguese language courses in secondary school.
It contains a lot of interesting social,
gender and study information about students.

There are several (382) students that belong to both datasets.
These students can be identified by searching for identical attributes
that characterize each student, as shown in the annexed R file.

The dataset contains in total 395 math-course-students samples and 
649 portugese-language-studens samples.


\section{Clustering Dalc and Walc attributes into one binary attribute}

We aim to build a model that would perform binary classification --
whether student can be considered drinking alcohol regularly or not.
The dataset provides 2 attributes:
\begin{itemize}
    \item Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
    \item Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
\end{itemize}
2D histogram visualization is shown on figure \ref{fig:hist2D}.

Using k-means algorithm (k=2) with initial centers in (1,1) and (3,3), we got clustering as shown on figure \ref{fig:clust}.
The clustering is done on merged data of math and portugese-language students (with removed duplicates).
Since workday alcohol consumption in case of students seems
to be more likely perceived as a criterium of classyfying then as
regulary drinking alcohol,
we decided to increase importance of Dalc attribute.
We did that by multiplying Dalc attribute by empirically factor of 1.5, and got clustering \ref{fig:clust2}.

% TODO: think about following
% We maximize consistency within 2 clusters of data using Silhouette coeficient
% (\url{https://en.wikipedia.org/wiki/Silhouette_(clustering)}).
% We use L2 distance.

\begin{figure}[h]
    \caption[]{2D histogram of Dalc and Walc attributes}
    \centering
    \includegraphics[page=1,width=1.0\textwidth]{../Rplots.pdf}
    \label{fig:hist2D}
\end{figure}

\begin{figure}[h]
    \caption[]{Clustering with k-means algorithm. (1: non-drinking, 2: drinking)}
    \centering
    \includegraphics[page=2,width=1.0\textwidth]{../Rplots.pdf}
    \label{fig:clust}
\end{figure}

\begin{figure}[h]
    \caption[]{Clustering with k-means algorithm (1: non-drinking, 2: drinking). Importance of Dalc attribute increased.}
    \centering
    \includegraphics[page=3,width=1.0\textwidth]{../Rplots.pdf}
    \label{fig:clust2}
\end{figure}

\section{Experiments with single decision trees}

Accuracy of decision tree shouldn't give better results than random forest,
so we trained several single decision trees to establish
an upper limit of desired error rate for random forests.

In accuracy measuring, we use cross-validation with 8 partitions.

In order to get general insight into the statistics, we visualized 2 simple decision trees.
Figure \ref{fig:single1} shows result for math studens,
figure \ref{fig:single2} for portuguese-language studens.

\begin{figure}[h]
    \caption[]{Simple single decision tree for math students}
    \centering
    \includegraphics[page=4,width=1.0\textwidth]{../Rplots.pdf}
    \label{fig:single1}
\end{figure}

\begin{figure}[h]
    \caption[]{Simple single decision tree for portugese-language students}
    \centering
    \includegraphics[page=6,width=1.0\textwidth]{../Rplots.pdf}
    \label{fig:single2}
\end{figure}

\section{Experiments with random forest}
TODO


\end{document}
